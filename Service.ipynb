{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87a1e3f6-88d3-430e-ada7-3f106d9a038a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request, send_from_directory, redirect, url_for, flash\n",
    "import os\n",
    "import pandas as pd\n",
    "import lxml\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import cx_Oracle\n",
    "app = Flask(__name__)\n",
    "app.secret_key = 'your_secret_key_here'\n",
    "app.config['MAX_CONTENT_LENGTH'] = 20 * 1024 * 1024 * 1024  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba30d8a",
   "metadata": {},
   "source": [
    "Conncting to oracle Database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e631d337",
   "metadata": {},
   "outputs": [],
   "source": [
    "##dsn_tns = cx_Oracle.makedsn('pc0308', '1521', service_name='XE')\n",
    "##conn = cx_Oracle.connect(user='ivan', password='password', dsn=dsn_tns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81d885f",
   "metadata": {},
   "source": [
    "Uploading csv file (later maybe removed and replaced with database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8120544-16c8-42f9-a4de-3348182451b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "UPLOAD_FOLDER = 'uploads'\n",
    "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n",
    "\n",
    "uploaded_tables = {}  \n",
    "\n",
    "@app.route('/', methods=['GET', 'POST'])\n",
    "def upload_files():\n",
    "    global uploaded_tables\n",
    "    \n",
    "    if request.method == 'POST':\n",
    "        files = request.files.getlist('file')\n",
    "\n",
    "        for file in files:\n",
    "            if file.filename != '':\n",
    "                file_path = os.path.join(app.config['UPLOAD_FOLDER'], file.filename)\n",
    "                file.save(file_path)\n",
    "                data = pd.read_csv(file_path)\n",
    "                uploaded_tables[file.filename] = data.to_html(index=False) \n",
    "    \n",
    "    return render_template('index.html', uploaded_files=uploaded_tables.keys())\n",
    "\n",
    "\n",
    "\n",
    "@app.route('/uploads/<filename>')\n",
    "def display_uploaded(filename):\n",
    "    table_html = uploaded_tables.get(filename, None)\n",
    "    if table_html is not None:\n",
    "        \n",
    "        df = pd.read_html(table_html, header=0)[0]\n",
    "        \n",
    "       \n",
    "        column_options = [col for col in df.columns if not col.startswith(\"Unnamed\")]\n",
    "        \n",
    "        return render_template('uploaded.html', filename=filename, table=table_html, column_options=column_options)\n",
    "    else:\n",
    "        return \"File not found.\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "641ff72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/all_tables', methods=['GET'])\n",
    "def display_all_tables():\n",
    "   \n",
    "    if uploaded_tables:\n",
    "        common_columns = set(pd.read_html(next(iter(uploaded_tables.values())), flavor='html5lib')[0].columns)\n",
    "        for table_html in uploaded_tables.values():\n",
    "            df = pd.read_html(table_html, flavor='html5lib')[0]\n",
    "            common_columns.intersection_update(df.columns)\n",
    "    else:\n",
    "        common_columns = set()\n",
    "    \n",
    "    return render_template('all_tables.html', uploaded_tables=uploaded_tables, common_columns=common_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baaa2ca4",
   "metadata": {},
   "source": [
    "Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3730aaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/merge_tables', methods=['POST'])\n",
    "def merge_tables():\n",
    "    tables_to_merge = request.form.getlist('tables_to_merge')\n",
    "    merge_attribute = request.form.get('merge_attribute')\n",
    "\n",
    "    dfs = [pd.read_html(uploaded_tables[filename], flavor='html5lib')[0] for filename in tables_to_merge]\n",
    "\n",
    "   \n",
    "    merged_df = dfs[0]\n",
    "    \n",
    "   \n",
    "    for df in dfs[1:]:\n",
    "        merged_df = pd.merge(merged_df, df, on=merge_attribute, how='outer')\n",
    "\n",
    "    \n",
    "    merged_filename = \"merged_\" + \"_\".join(tables_to_merge)\n",
    "    uploaded_tables[merged_filename] = merged_df.to_html(index=False)\n",
    "\n",
    "    return redirect(url_for('display_all_tables'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537f97c2",
   "metadata": {},
   "source": [
    "Option to remove unwanted columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73ff479a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/uploads/<filename>/remove_column', methods=['POST'])\n",
    "def remove_column(filename):\n",
    "    selected_column = request.form.get('selected_column')\n",
    "    \n",
    "    table_html = uploaded_tables.get(filename, None)\n",
    "    if table_html:\n",
    "        df = pd.read_html(table_html, header=0)[0]\n",
    "    else:\n",
    "        flash(\"Error accessing the DataFrame.\", 'error')\n",
    "        return redirect(url_for('display_uploaded', filename=filename))\n",
    "\n",
    "    if selected_column:\n",
    "        try:\n",
    "            df.drop(columns=[selected_column], inplace=True)\n",
    "            uploaded_tables[filename] = df.to_html()  \n",
    "            flash(f\"Column '{selected_column}' has been removed from the DataFrame.\", 'success')\n",
    "        except KeyError:\n",
    "            flash(f\"Column '{selected_column}' not found in the DataFrame.\", 'error')\n",
    "    else:\n",
    "        flash(\"Please select a column to remove.\", 'error')\n",
    "\n",
    "    return redirect(url_for('display_uploaded', filename=filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "515f4581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_column_and_values(df, old_column_name, new_column_name_prefix):\n",
    "  \n",
    "    unique_values = df[old_column_name].unique()\n",
    "    value_mapping = {unique_values[i]: f\"{new_column_name_prefix}_{i+1}\" for i in range(len(unique_values))}\n",
    "    df[new_column_name_prefix] = df[old_column_name].map(value_mapping)\n",
    "    \n",
    "    if old_column_name != new_column_name_prefix:\n",
    "        df = df.drop(old_column_name, axis=1)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b63cbe32",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/uploads/<filename>/rename_column', methods=['POST'])\n",
    "def rename_column(filename):\n",
    "    old_column_name = request.form.get('old_column_name')\n",
    "    new_column_name_prefix = request.form.get('new_column_name_prefix')\n",
    "\n",
    "    table_html = uploaded_tables.get(filename, None)\n",
    "    if table_html:\n",
    "        df = pd.read_html(table_html, header=0)[0]\n",
    "    else:\n",
    "        flash(\"Error accessing the DataFrame.\", 'error')\n",
    "        return redirect(url_for('display_uploaded', filename=filename))\n",
    "\n",
    "    if old_column_name and new_column_name_prefix:\n",
    "        df = rename_column_and_values(df, old_column_name, new_column_name_prefix)\n",
    "        uploaded_tables[filename] = df.to_html(index=False)\n",
    "        flash(f\"Column '{old_column_name}' and its values have been renamed.\", 'success')\n",
    "    else:\n",
    "        flash(\"Please select a column and enter a new prefix.\", 'error')\n",
    "\n",
    "    return redirect(url_for('display_uploaded', filename=filename))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505cc818",
   "metadata": {},
   "source": [
    "Fucntions to preform on a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "20f90e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/uploads/<filename>', methods=['POST'])\n",
    "def apply_action(filename):\n",
    "    table_html = uploaded_tables.get(filename, None)\n",
    "    if table_html is not None:\n",
    "        action = request.form.get('action')\n",
    "        data_html = uploaded_tables[filename]\n",
    "        data = pd.read_html(data_html, flavor='html5lib')[0]\n",
    "        if action == 'remove_duplicates':\n",
    "            data = remove_duplicates(data)\n",
    "        elif action == 'remove_missing_values':\n",
    "            data = remove_missing_values(data)\n",
    "        elif action == 'convert_boolean_to_binary':\n",
    "            data = convert_boolean_to_binary(data)\n",
    "        elif action == 'min_max_scaling':\n",
    "            data = min_max_scaling(data)\n",
    "        elif action == 'z_score_normalization':\n",
    "            data = z_score_normalization(data)\n",
    "        uploaded_tables[filename] = data.to_html(index=False)\n",
    "        return redirect(url_for('display_uploaded', filename=filename))\n",
    "    else:\n",
    "        return \"File not found.\"\n",
    "\n",
    "def convert_boolean_to_binary(df):\n",
    "    return df.applymap(lambda x: int(x) if isinstance(x, bool) else x)\n",
    "\n",
    "def remove_duplicates(df):\n",
    "    return df.drop_duplicates()\n",
    "\n",
    "def remove_missing_values(df):\n",
    "    return df.dropna()\n",
    "\n",
    "def min_max_scaling(df):\n",
    "    scaler = MinMaxScaler()\n",
    "    return pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "\n",
    "def z_score_normalization(df):\n",
    "    scaler = StandardScaler()\n",
    "    return pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f863cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add missing data finder\n",
    "# add missing data filling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a8c09728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_datetime_column(df, datetime_col='DateTime'):\n",
    "    \"\"\"Splits a combined date-time column into separate date and time columns.\"\"\"\n",
    "    df[datetime_col] = pd.to_datetime(df[datetime_col])\n",
    "    df['Date'] = df[datetime_col].dt.date\n",
    "    df['Time'] = df[datetime_col].dt.time\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55e89ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/uploads/<filename>/split_datetime', methods=['POST'])\n",
    "def split_datetime(filename):\n",
    "    datetime_column = request.form.get('datetime_column')\n",
    "    \n",
    "    table_html = uploaded_tables.get(filename, None)\n",
    "    if table_html:\n",
    "        df = pd.read_html(table_html, header=0)[0]\n",
    "        df = df.loc[:, ~df.columns.str.startswith('Unnamed')]\n",
    "\n",
    "        # Split the combined date-time column\n",
    "        df = split_datetime_column(df, datetime_col=datetime_column)\n",
    "\n",
    "        uploaded_tables[filename] = df.to_html(index=False)\n",
    "        flash(f\"Date-Time column '{datetime_column}' has been split.\", 'success')\n",
    "    else:\n",
    "        flash(\"Error accessing the DataFrame.\", 'error')\n",
    "\n",
    "    return redirect(url_for('display_uploaded', filename=filename))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c0e899",
   "metadata": {},
   "source": [
    "Resempling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f61ad640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_data_on_column(df, datetime_col='DateTime', interval=15):\n",
    "    \"\"\"Resamples the data based on the provided interval.\"\"\"\n",
    "    df.set_index(datetime_col, inplace=True)\n",
    "    df_resampled = df.resample(f'{interval}T').mean()\n",
    "    \n",
    "    def handle_outliers(row):\n",
    "        minute = row.name.minute\n",
    "        if minute % interval < interval / 2:\n",
    "            return (minute // interval) * interval\n",
    "        else:\n",
    "            return ((minute // interval) + 1) * interval\n",
    "\n",
    "    df_resampled['NewMinute'] = df_resampled.apply(handle_outliers, axis=1)\n",
    "    \n",
    "    return df_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "722ef328",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/uploads/<filename>/resample', methods=['POST'])\n",
    "def resample_route(filename):\n",
    "    interval = request.form.get('interval', type=int)\n",
    "    datetime_col = request.form.get('datetime_column')  # Fetch the selected datetime column\n",
    "    \n",
    "    if not interval:\n",
    "        flash(\"Please specify a resampling interval.\", 'error')\n",
    "        return redirect(url_for('display_uploaded', filename=filename))\n",
    "\n",
    "    table_html = uploaded_tables.get(filename, None)\n",
    "    if table_html:\n",
    "        df = pd.read_html(table_html, header=0)[0]\n",
    "        df = df.loc[:, ~df.columns.str.startswith('Unnamed')]\n",
    "        \n",
    "        if datetime_col not in df.columns:\n",
    "            flash(f\"The specified date-time column '{datetime_col}' does not exist.\", 'error')\n",
    "            return redirect(url_for('display_uploaded', filename=filename))\n",
    "\n",
    "        df_resampled = resample_data_on_column(df, datetime_col=datetime_col, interval=interval)\n",
    "\n",
    "        uploaded_tables[filename] = df_resampled.to_html(index=False)\n",
    "        flash(f\"Data has been resampled to {interval}-minute intervals.\", 'success')\n",
    "    else:\n",
    "        flash(\"Error accessing the DataFrame.\", 'error')\n",
    "\n",
    "    return redirect(url_for('display_uploaded', filename=filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9e034640-6c53-482a-aa74-f2591d4037fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.216.115:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [04/Sep/2023 12:00:53] \"POST / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2023 12:00:53] \"GET /static/styles.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [04/Sep/2023 12:00:56] \"GET /uploads/train.csv HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2023 12:00:56] \"GET /static/styles.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [04/Sep/2023 12:01:10] \"POST / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2023 12:01:10] \"GET /static/styles.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [04/Sep/2023 12:01:11] \"GET /uploads/Plant_1_Generation_Data%20-%20Copy.csv HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2023 12:01:11] \"GET /static/styles.css HTTP/1.1\" 304 -\n",
      "C:\\Users\\jovev\\AppData\\Local\\Temp\\ipykernel_10228\\660582031.py:3: UserWarning: Parsing dates in %d-%m-%Y %H:%M format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df[datetime_col] = pd.to_datetime(df[datetime_col])\n",
      "127.0.0.1 - - [04/Sep/2023 12:01:20] \"POST /uploads/Plant_1_Generation_Data%20-%20Copy.csv/split_datetime HTTP/1.1\" 302 -\n",
      "127.0.0.1 - - [04/Sep/2023 12:01:21] \"GET /uploads/Plant_1_Generation_Data%20-%20Copy.csv HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2023 12:01:21] \"GET /static/styles.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [04/Sep/2023 12:01:47] \"POST /uploads/Plant_1_Generation_Data%20-%20Copy.csv/remove_column HTTP/1.1\" 302 -\n",
      "127.0.0.1 - - [04/Sep/2023 12:01:48] \"GET /uploads/Plant_1_Generation_Data%20-%20Copy.csv HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2023 12:01:48] \"GET /static/styles.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [04/Sep/2023 12:02:03] \"GET /uploads/Plant_1_Generation_Data%20-%20Copy.csv HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2023 12:02:04] \"GET /uploads/Plant_1_Generation_Data%20-%20Copy.csv HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2023 12:02:09] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2023 12:02:09] \"GET /static/styles.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [04/Sep/2023 12:02:16] \"POST / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2023 12:02:16] \"GET /static/styles.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [04/Sep/2023 12:02:17] \"GET /uploads/Plant_1_Generation_Data%20-%20Copy.csv HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2023 12:02:17] \"GET /static/styles.css HTTP/1.1\" 304 -\n",
      "C:\\Users\\jovev\\AppData\\Local\\Temp\\ipykernel_10228\\660582031.py:3: UserWarning: Parsing dates in %d-%m-%Y %H:%M format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df[datetime_col] = pd.to_datetime(df[datetime_col])\n",
      "127.0.0.1 - - [04/Sep/2023 12:03:49] \"POST /uploads/Plant_1_Generation_Data%20-%20Copy.csv/split_datetime HTTP/1.1\" 302 -\n",
      "127.0.0.1 - - [04/Sep/2023 12:03:50] \"GET /uploads/Plant_1_Generation_Data%20-%20Copy.csv HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2023 12:03:50] \"GET /static/styles.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [04/Sep/2023 12:03:58] \"POST /uploads/Plant_1_Generation_Data%20-%20Copy.csv/remove_column HTTP/1.1\" 302 -\n",
      "127.0.0.1 - - [04/Sep/2023 12:03:58] \"GET /uploads/Plant_1_Generation_Data%20-%20Copy.csv HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2023 12:03:58] \"GET /static/styles.css HTTP/1.1\" 304 -\n",
      "[2023-09-04 12:04:22,998] ERROR in app: Exception on /uploads/Plant_1_Generation_Data - Copy.csv/resample [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3653, in get_loc\n",
      "    return self._engine.get_loc(casted_key)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"pandas\\_libs\\index.pyx\", line 147, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas\\_libs\\index.pyx\", line 176, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas\\_libs\\hashtable_class_helper.pxi\", line 7080, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "  File \"pandas\\_libs\\hashtable_class_helper.pxi\", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "KeyError: 'DateTime'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\flask\\app.py\", line 2190, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\flask\\app.py\", line 1486, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\flask\\app.py\", line 1484, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\flask\\app.py\", line 1469, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jovev\\AppData\\Local\\Temp\\ipykernel_10228\\894212254.py\", line 14, in resample_route\n",
      "    df = split_datetime_column(df, datetime_col='DateTime')\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jovev\\AppData\\Local\\Temp\\ipykernel_10228\\660582031.py\", line 3, in split_datetime_column\n",
      "    df[datetime_col] = pd.to_datetime(df[datetime_col])\n",
      "                                      ~~^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py\", line 3761, in __getitem__\n",
      "    indexer = self.columns.get_loc(key)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3655, in get_loc\n",
      "    raise KeyError(key) from err\n",
      "KeyError: 'DateTime'\n",
      "127.0.0.1 - - [04/Sep/2023 12:04:23] \"POST /uploads/Plant_1_Generation_Data%20-%20Copy.csv/resample HTTP/1.1\" 500 -\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
